# Machine Learning Labs - Regression, Classification & Neural Networks

## ðŸ“Œ Overview  
This repository contains **four Jupyter Notebooks** for hands-on **Machine Learning (ML) experiments**, covering **Regression, Classification, Neural Networks, and Machine Learning Best Practices**:

- **Lab 1: Regression Analysis** â†’ Linear & Ridge Regression  
- **Lab 2: Classification Analysis** â†’ Logistic Regression & Regularization  
- **Lab 3: Neural Networks** â†’ Multi-layer Feedforward Neural Networks (MLP)  
- **Lab 4: ML Advice & Best Practices** â†’ Bias-Variance Tradeoff, Regularization, and Model Optimization  

Each lab demonstrates:  
- **Synthetic data generation and preprocessing**  
- **Model training using Scikit-Learn and TensorFlow/Keras**  
- **Regularization techniques to improve generalization**  
- **Performance evaluation through metrics and visualizations**  
- **Hyperparameter tuning and optimization strategies**  

---

## ðŸ“‚ Files  

- **`Lab1-Regression.ipynb`** â†’ Implements:  
  - **Linear Regression** (`LinearRegression`)  
  - **Ridge Regression** (`Ridge`)  
  - **Comparison of Regularized vs. Unregularized models**  
  - **Mean Squared Error (MSE) and Prediction Analysis**  

- **`Lab2-Classification.ipynb`** â†’ Implements:  
  - **Logistic Regression** (`LogisticRegression`)  
  - **Ridge Classifier (`RidgeClassifier`)**  
  - **Decision boundary visualization**  
  - **Accuracy, confusion matrix, and evaluation metrics**  

- **`Lab3-NeuralNetworks.ipynb`** â†’ Implements:  
  - **Multi-layer Feedforward Neural Networks (MLP) using TensorFlow/Keras**  
  - **Activation Functions: ReLU, Sigmoid, Softmax**  
  - **Model Compilation & Optimization (Adam, SGD, etc.)**  
  - **Regularization (L2, Dropout) to prevent overfitting**  
  - **Hyperparameter tuning for improved performance**  

- **`Lab4-Advice.ipynb`** â†’ Implements:  
  - **Bias-Variance Tradeoff: Understanding underfitting vs. overfitting**  
  - **Learning Curves: Visualizing model performance with different data sizes**  
  - **Regularization: L1 (Lasso) & L2 (Ridge) to control model complexity**  
  - **Hyperparameter Tuning: Adjusting learning rate, regularization strength, and model parameters**  
  - **Error Analysis: Diagnosing issues in training & test performance**  

---

## ðŸ”§ Setup & Requirements  
To run these notebooks, install the required dependencies:  
```bash
pip install numpy pandas scikit-learn matplotlib seaborn tensorflow
```
Then, open the notebooks using:  
```bash
jupyter notebook
```
